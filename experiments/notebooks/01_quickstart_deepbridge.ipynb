{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start: DeepBridge for Fairness Detection\n",
    "\n",
    "This notebook demonstrates how to use the **DeepBridge** library for automated fairness detection.\n",
    "\n",
    "## What is DeepBridge?\n",
    "\n",
    "DeepBridge is a library for automated fairness analysis in machine learning datasets. It provides:\n",
    "- **Auto-detection** of sensitive attributes (race, gender, age, etc.)\n",
    "- **Fairness metrics** computation (demographic parity, equalized odds, etc.)\n",
    "- **Bias detection** with configurable thresholds\n",
    "- **EEOC/ECOA compliance** checking\n",
    "\n",
    "## Installation\n",
    "\n",
    "```bash\n",
    "# Install DeepBridge from local source\n",
    "pip install -e /home/guhaase/projetos/DeepBridge/deepbridge\n",
    "```\n",
    "\n",
    "**Estimated time**: 5-10 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DeepBridge\n",
    "from deepbridge import DBDataset\n",
    "\n",
    "# Other libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Sample Data\n",
    "\n",
    "Let's create a simple dataset with intentional bias to demonstrate DeepBridge's capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create sample data (500 samples)\n",
    "n_samples = 500\n",
    "\n",
    "data = {\n",
    "    'age': np.random.randint(18, 70, n_samples),\n",
    "    'income': np.random.randint(20000, 150000, n_samples),\n",
    "    'education_years': np.random.randint(8, 20, n_samples),\n",
    "    'gender': np.random.choice(['Male', 'Female'], n_samples),\n",
    "    'race': np.random.choice(['White', 'Black', 'Asian', 'Hispanic'], n_samples),\n",
    "}\n",
    "\n",
    "# Create target with intentional bias:\n",
    "# - Higher approval for males (70% vs 50%)\n",
    "# - Higher approval for White race (65% vs 50%)\n",
    "approved = []\n",
    "for i in range(n_samples):\n",
    "    base_prob = 0.5\n",
    "    \n",
    "    # Gender bias\n",
    "    if data['gender'][i] == 'Male':\n",
    "        base_prob += 0.2\n",
    "    \n",
    "    # Race bias\n",
    "    if data['race'][i] == 'White':\n",
    "        base_prob += 0.15\n",
    "    \n",
    "    # Random approval based on biased probability\n",
    "    approved.append(1 if np.random.random() < base_prob else 0)\n",
    "\n",
    "data['approved'] = approved\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(f\"✓ Created dataset with {len(df)} samples\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create DBDataset\n",
    "\n",
    "The `DBDataset` class is the main entry point for DeepBridge. It automatically detects sensitive attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DBDataset (auto-detects sensitive attributes)\n",
    "dataset = DBDataset(\n",
    "    data=df,\n",
    "    target_column='approved'\n",
    ")\n",
    "\n",
    "print(\"✓ DBDataset created successfully\")\n",
    "print(f\"\\nDetected sensitive attributes: {dataset.detected_sensitive_attributes}\")\n",
    "print(f\"Target column: {dataset.target_column}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Fairness\n",
    "\n",
    "Run fairness analysis to detect bias in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run fairness analysis\n",
    "results = dataset.analyze_fairness()\n",
    "\n",
    "print(\"✓ Fairness analysis complete\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FAIRNESS ANALYSIS RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Examine Results by Attribute\n",
    "\n",
    "Let's look at fairness metrics for each sensitive attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if results is a dictionary or has specific structure\n",
    "if hasattr(results, 'to_dict'):\n",
    "    results_dict = results.to_dict()\n",
    "elif isinstance(results, dict):\n",
    "    results_dict = results\n",
    "else:\n",
    "    results_dict = {'summary': str(results)}\n",
    "\n",
    "# Display results\n",
    "for key, value in results_dict.items():\n",
    "    print(f\"\\n{key.upper()}:\")\n",
    "    print(\"-\" * 40)\n",
    "    if isinstance(value, (dict, pd.DataFrame)):\n",
    "        print(value)\n",
    "    else:\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Check Specific Attributes\n",
    "\n",
    "Examine bias for specific attributes like gender and race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate approval rates by gender\n",
    "print(\"APPROVAL RATES BY GENDER:\")\n",
    "print(\"=\"*40)\n",
    "gender_stats = df.groupby('gender')['approved'].agg(['mean', 'count'])\n",
    "gender_stats.columns = ['Approval Rate', 'Count']\n",
    "print(gender_stats)\n",
    "print(f\"\\nDifference: {gender_stats['Approval Rate'].max() - gender_stats['Approval Rate'].min():.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "\n",
    "# Calculate approval rates by race\n",
    "print(\"\\nAPPROVAL RATES BY RACE:\")\n",
    "print(\"=\"*40)\n",
    "race_stats = df.groupby('race')['approved'].agg(['mean', 'count'])\n",
    "race_stats.columns = ['Approval Rate', 'Count']\n",
    "print(race_stats)\n",
    "print(f\"\\nDifference: {race_stats['Approval Rate'].max() - race_stats['Approval Rate'].min():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interpretation\n",
    "\n",
    "### What do these results mean?\n",
    "\n",
    "**Demographic Parity**: \n",
    "- Measures if different groups receive positive outcomes at similar rates\n",
    "- Threshold: difference > 0.1 indicates potential bias\n",
    "\n",
    "**Equalized Odds**:\n",
    "- Measures if true positive rates and false positive rates are similar across groups\n",
    "- Important for fair decision-making\n",
    "\n",
    "**Disparate Impact**:\n",
    "- Ratio of approval rates between groups\n",
    "- EEOC 80% rule: ratio should be > 0.8\n",
    "\n",
    "### Expected Results:\n",
    "\n",
    "Since we intentionally created bias:\n",
    "- **Gender**: Males should have ~70% approval vs Females ~50% (difference ~0.20)\n",
    "- **Race**: White should have ~65% approval vs others ~50% (difference ~0.15)\n",
    "\n",
    "Both violations should be **DETECTED** by DeepBridge! ⚠️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load Real Dataset (Optional)\n",
    "\n",
    "Try DeepBridge with a real-world dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to case study datasets\n",
    "data_dir = Path(\"../../data/case_studies\")\n",
    "\n",
    "# Check available case studies\n",
    "if data_dir.exists():\n",
    "    case_studies = [d.name for d in data_dir.iterdir() if d.is_dir()]\n",
    "    print(f\"Available case studies: {case_studies}\")\n",
    "    \n",
    "    # Example: Load Adult Income dataset if available\n",
    "    adult_path = data_dir / \"adult\" / \"adult.csv\"\n",
    "    if adult_path.exists():\n",
    "        print(f\"\\n✓ Loading: {adult_path}\")\n",
    "        adult_df = pd.read_csv(adult_path)\n",
    "        print(f\"Shape: {adult_df.shape}\")\n",
    "        print(f\"Columns: {list(adult_df.columns)}\")\n",
    "        \n",
    "        # Create DBDataset (assuming 'income' is the target)\n",
    "        if 'income' in adult_df.columns:\n",
    "            adult_dataset = DBDataset(data=adult_df, target_column='income')\n",
    "            print(f\"\\nDetected attributes: {adult_dataset.detected_sensitive_attributes}\")\n",
    "            \n",
    "            # Analyze fairness\n",
    "            adult_results = adult_dataset.analyze_fairness()\n",
    "            print(\"\\nFairness Analysis:\")\n",
    "            print(adult_results)\n",
    "    else:\n",
    "        print(f\"⚠️  Adult dataset not found at {adult_path}\")\n",
    "else:\n",
    "    print(f\"⚠️  Case studies directory not found: {data_dir}\")\n",
    "    print(\"To use real datasets, ensure data/case_studies/ is populated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "### What we learned:\n",
    "\n",
    "1. **Import DeepBridge**: `from deepbridge import DBDataset`\n",
    "2. **Create dataset**: `DBDataset(data=df, target_column='target')`\n",
    "3. **Auto-detection**: DeepBridge automatically identifies sensitive attributes\n",
    "4. **Analyze fairness**: `dataset.analyze_fairness()`\n",
    "5. **Interpret results**: Check demographic parity, equalized odds, disparate impact\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- **Notebook 02**: Explore case studies (COMPAS, Adult Income, German Credit, Bank Marketing)\n",
    "- **Run experiments**: Execute `experiments/scripts/exp*.py` to reproduce paper results\n",
    "- **Read documentation**: See `docs/quickstart.md` and `docs/installation.md`\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- **DeepBridge source**: `/home/guhaase/projetos/DeepBridge/deepbridge`\n",
    "- **Documentation**: `docs/`\n",
    "- **Case studies**: `data/case_studies/`\n",
    "- **Experiments**: `experiments/scripts/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**End of Quick Start**\n",
    "\n",
    "Questions or issues? Check the [troubleshooting guide](../../docs/troubleshooting.md) or open an issue on GitHub."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
