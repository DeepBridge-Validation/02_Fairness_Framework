# Scripts de Experimentos - DeepBridge Fairness

Documenta√ß√£o completa de todos os scripts experimentais para valida√ß√£o do paper.

---

## üìÅ Estrutura

```
scripts/
‚îú‚îÄ‚îÄ 00_setup_environment.sh         # Setup automatizado
‚îú‚îÄ‚îÄ 01_collect_datasets.py          # Coleta de 500 datasets
‚îú‚îÄ‚îÄ 02_annotate_ground_truth.py     # Anota√ß√£o manual (2 anotadores)
‚îú‚îÄ‚îÄ exp1_auto_detection.py          # Exp 1: Auto-detec√ß√£o
‚îú‚îÄ‚îÄ exp2_usability_study.py         # Exp 2: Usabilidade (SUS/TLX)
‚îú‚îÄ‚îÄ exp3_eeoc_validation.py         # Exp 3: Valida√ß√£o EEOC/ECOA
‚îú‚îÄ‚îÄ exp4_case_studies.py            # Exp 4: Case studies
‚îú‚îÄ‚îÄ exp5_performance.py             # Exp 5: Performance benchmarks
‚îú‚îÄ‚îÄ run_all_experiments.sh          # Master script (executa todos)
‚îî‚îÄ‚îÄ utils.py                        # Fun√ß√µes utilit√°rias
```

---

## üöÄ QUICK START

### 1. Setup Inicial (1 vez)

```bash
# Configurar ambiente
./00_setup_environment.sh

# Ativar
source ../venv_fairness/bin/activate

# Verificar
python -c "import pandas, numpy, scipy; print('‚úÖ OK')"
```

### 2. Prepara√ß√£o de Dados (Semana 1)

```bash
# Coletar 500 datasets
python 01_collect_datasets.py --target 500

# Anotar ground truth (2 anotadores independentes)
python 02_annotate_ground_truth.py --annotator 1 --n-datasets 500
python 02_annotate_ground_truth.py --annotator 2 --n-datasets 500

# Calcular inter-rater agreement
python 02_annotate_ground_truth.py --calculate-agreement
```

### 3. Executar Experimentos (Semanas 2-12)

```bash
# Op√ß√£o 1: Executar todos de uma vez
./run_all_experiments.sh

# Op√ß√£o 2: Executar individualmente
python exp1_auto_detection.py --ground-truth ../data/ground_truth_final.json
python exp2_usability_study.py --participant-id P01
python exp3_eeoc_validation.py --n-datasets 100
python exp4_case_studies.py --datasets compas,german,adult,healthcare
python exp5_performance.py --mode full --n-repeats 10
```

---

## üìã DETALHAMENTO DOS SCRIPTS

### **00_setup_environment.sh**

**Prop√≥sito**: Configurar ambiente Python completo

**Execu√ß√£o**:
```bash
./00_setup_environment.sh
```

**O que faz**:
- Cria ambiente virtual `venv_fairness`
- Instala todas depend√™ncias (pandas, numpy, scipy, sklearn, aif360, fairlearn, etc.)
- Configura Jupyter kernel
- Salva `requirements.txt`
- Testa imports

**Output esperado**:
- ‚úÖ Ambiente funcional em ~5 minutos
- Arquivo `requirements.txt` gerado

---

### **01_collect_datasets.py**

**Prop√≥sito**: Coletar 500 datasets para valida√ß√£o

**Execu√ß√£o**:
```bash
# Full (500 datasets)
python 01_collect_datasets.py --target 500 --output ../data/datasets

# Quick test (50 datasets)
python 01_collect_datasets.py --target 50
```

**Fontes**:
- UCI ML Repository (50 datasets)
- OpenML (50 datasets)
- Datasets sint√©ticos (400 datasets)

**Output**:
- `../data/datasets/` - 500 arquivos CSV
- `../data/datasets_metadata.csv` - Cat√°logo completo

**Tempo**: ~30 minutos

---

### **02_annotate_ground_truth.py**

**Prop√≥sito**: Anota√ß√£o manual de atributos sens√≠veis

**Execu√ß√£o**:
```bash
# Anotador 1
python 02_annotate_ground_truth.py --annotator 1 --n-datasets 500

# Anotador 2 (independente)
python 02_annotate_ground_truth.py --annotator 2 --n-datasets 500

# Calcular Cohen's Kappa
python 02_annotate_ground_truth.py --calculate-agreement
```

**Interface**:
- CLI interativa
- Mostra colunas do dataset
- Categorias EEOC/ECOA (1-9)
- Salva progresso automaticamente

**Output**:
- `../data/annotations_annotator_1.json`
- `../data/annotations_annotator_2.json`
- `../data/inter_rater_agreement_report.json`

**Meta**: Kappa > 0.75 (agreement substancial)

**Tempo**: ~60 horas (2 anotadores √ó 30h)

---

### **exp1_auto_detection.py**

**Experimento 1: Auto-Detec√ß√£o de Atributos Sens√≠veis**

**Execu√ß√£o**:
```bash
# Full experiment
python exp1_auto_detection.py \
    --ground-truth ../data/ground_truth_final.json \
    --datasets-dir ../data/datasets \
    --output ../results/exp1_auto_detection

# Ajustar threshold
python exp1_auto_detection.py --threshold 0.80 --ground-truth ...
```

**Algoritmo**:
1. Fuzzy matching de nomes de colunas
2. Compara√ß√£o com keywords EEOC/ECOA
3. Threshold de similaridade (default: 0.75)

**M√©tricas**:
- Precision, Recall, F1 Score (por dataset)
- Micro e Macro averages
- Confusion matrix
- An√°lise de erros (FP/FN)

**Meta**:
- F1 ‚â• 0.85 (paper claim: 0.90)

**Output**:
- `exp1_results.json` - Resultados completos
- `exp1_report.txt` - Relat√≥rio textual
- `metrics_distribution.png` - Histogramas
- `precision_recall_scatter.png` - Scatter plot

**Tempo**: ~2 horas (500 datasets)

---

### **exp2_usability_study.py**

**Experimento 2: Estudo de Usabilidade**

**Execu√ß√£o**:
```bash
# Sess√£o individual (N=20)
python exp2_usability_study.py --participant-id P01 --mode interactive
python exp2_usability_study.py --participant-id P02 --mode interactive
# ... (at√© P20)

# An√°lise agregada
python exp2_usability_study.py --analyze --input ../results/exp2_usability
```

**Protocolo (60 min/participante)**:
1. **Briefing** (5 min) - Explicar DeepBridge
2. **5 Tarefas** (30 min):
   - Tarefa 1: Carregar dataset e auto-detectar
   - Tarefa 2: An√°lise de fairness (3 m√©tricas)
   - Tarefa 3: Verifica√ß√£o EEOC/ECOA
   - Tarefa 4: Ajustar threshold
   - Tarefa 5: Exportar relat√≥rio
3. **Question√°rios** (10 min):
   - SUS (10 quest√µes, escala 1-5)
   - NASA-TLX (6 dimens√µes, escala 0-100)
4. **Entrevista** (15 min) - Semi-estruturada

**M√©tricas**:
- SUS Score (0-100): Meta ‚â• 75 (claim: 85.2)
- NASA-TLX (0-100): Meta < 40
- Taxa de sucesso: Meta ‚â• 95%
- Tempo por tarefa

**Output**:
- `P01/session_complete.json` - Dados completos
- `aggregate_analysis.json` - An√°lise estat√≠stica
- `usability_scores.png` - Distribui√ß√µes SUS/TLX

**Tempo**: ~20 horas (20 participantes √ó 1h)

---

### **exp3_eeoc_validation.py**

**Experimento 3: Valida√ß√£o EEOC/ECOA**

**Execu√ß√£o**:
```bash
python exp3_eeoc_validation.py \
    --datasets-dir ../data/datasets \
    --output ../results/exp3_eeoc \
    --n-datasets 100
```

**Verifica√ß√µes**:
- 4/5 Rule (Disparate Impact)
- Statistical Parity (diferen√ßa < 0.2)
- Equal Opportunity (diferen√ßa < 0.1)
- Conformidade EEOC/ECOA

**Meta**:
- 100% precis√£o (sem margem de erro)

**Output**:
- `eeoc_validation_results.json`
- `eeoc_compliance_report.txt`
- `eeoc_violations.csv`

**Tempo**: ~1 hora (100 datasets)

---

### **exp4_case_studies.py**

**Experimento 4: Case Studies Detalhados**

**Execu√ß√£o**:
```bash
python exp4_case_studies.py \
    --datasets compas,german,adult,healthcare \
    --output ../results/exp4_case_studies
```

**4 Case Studies**:
1. **COMPAS** (Criminal Justice) - Recidivism prediction
2. **German Credit** (Finance) - Credit risk
3. **Adult Income** (Employment) - Income prediction
4. **Healthcare** (Medical) - Readmission prediction

**An√°lise por case**:
- Explora√ß√£o de dados
- Detec√ß√£o de bias
- Verifica√ß√£o EEOC
- Recomenda√ß√µes de mitiga√ß√£o
- Compara√ß√£o manual vs. DeepBridge (tempo)

**Output**:
- `compas/case_study_report.md`
- `compas/fairness_metrics.json`
- `compas/bias_analysis.png`
- (idem para german, adult, healthcare)

**Tempo**: ~8 horas (2h por case)

---

### **exp5_performance.py**

**Experimento 5: Performance Benchmarks**

**Execu√ß√£o**:
```bash
# Quick test
python exp5_performance.py --mode quick --n-repeats 3

# Full benchmark
python exp5_performance.py --mode full --n-repeats 10
```

**Compara√ß√µes**:
1. DeepBridge (autom√°tico)
2. An√°lise manual (estimado do exp2)
3. AIF360
4. Fairlearn

**Tamanhos de dataset**:
- 1,000 linhas
- 10,000 linhas
- 100,000 linhas

**M√©tricas**:
- Tempo de execu√ß√£o m√©dio
- Speedup (√ó)
- Statistical tests (paired t-test, Cohen's d)

**Meta**:
- Speedup ‚â• 2.5x vs. manual (claim: 2.9x)

**Output**:
- `performance_results.json`
- `performance_results.csv`
- `performance_comparison.png`
- `performance_comparison_bar.png`

**Tempo**: ~2 horas (full mode)

---

## üî¨ EXECU√á√ÉO COMPLETA (Master Script)

### **run_all_experiments.sh**

```bash
./run_all_experiments.sh
```

**O que faz**:
1. Verifica ambiente
2. Executa exp1-exp5 sequencialmente
3. Gera relat√≥rio consolidado
4. Valida todas as claims do paper

**Tempo total**: ~4 horas (assumindo dados j√° coletados)

---

## üìä VALIDA√á√ÉO DE CLAIMS

| Claim | Experimento | Meta | Script |
|-------|-------------|------|--------|
| F1 ‚â• 0.90 | Auto-detec√ß√£o | F1 ‚â• 0.85 | exp1 |
| SUS = 85.2 | Usabilidade | SUS ‚â• 75 | exp2 |
| Success rate ‚â• 95% | Usabilidade | 95% | exp2 |
| EEOC 100% accuracy | EEOC validation | 100% | exp3 |
| Speedup 2.9x | Performance | ‚â• 2.5x | exp5 |

---

## üìÇ OUTPUT ESPERADO

```
results/
‚îú‚îÄ‚îÄ exp1_auto_detection/
‚îÇ   ‚îú‚îÄ‚îÄ exp1_results.json
‚îÇ   ‚îú‚îÄ‚îÄ exp1_report.txt
‚îÇ   ‚îî‚îÄ‚îÄ *.png
‚îú‚îÄ‚îÄ exp2_usability/
‚îÇ   ‚îú‚îÄ‚îÄ P01/ ... P20/
‚îÇ   ‚îú‚îÄ‚îÄ aggregate_analysis.json
‚îÇ   ‚îî‚îÄ‚îÄ usability_scores.png
‚îú‚îÄ‚îÄ exp3_eeoc/
‚îÇ   ‚îú‚îÄ‚îÄ eeoc_validation_results.json
‚îÇ   ‚îî‚îÄ‚îÄ eeoc_compliance_report.txt
‚îú‚îÄ‚îÄ exp4_case_studies/
‚îÇ   ‚îú‚îÄ‚îÄ compas/
‚îÇ   ‚îú‚îÄ‚îÄ german/
‚îÇ   ‚îú‚îÄ‚îÄ adult/
‚îÇ   ‚îî‚îÄ‚îÄ healthcare/
‚îî‚îÄ‚îÄ exp5_performance/
    ‚îú‚îÄ‚îÄ performance_results.json
    ‚îú‚îÄ‚îÄ performance_results.csv
    ‚îî‚îÄ‚îÄ *.png
```

---

## ‚öôÔ∏è TROUBLESHOOTING

### Erro: "DeepBridge n√£o instalado"
```bash
# Op√ß√£o 1: Usar modo mock (testes)
export DEEPBRIDGE_MOCK=1
python exp1_auto_detection.py --quick

# Op√ß√£o 2: Instalar DeepBridge
pip install deepbridge
```

### Erro: "Ground truth n√£o encontrado"
```bash
# Criar ground truth primeiro
python 02_annotate_ground_truth.py --annotator 1 --n-datasets 10

# Consolidar anota√ß√µes
python -c "
import json
with open('../data/annotations_annotator_1.json') as f:
    data = json.load(f)
with open('../data/ground_truth_final.json', 'w') as f:
    json.dump(data, f, indent=2)
"
```

### Erro: "Mem√≥ria insuficiente"
```bash
# Reduzir tamanho de datasets
python exp1_auto_detection.py --n-datasets 100  # em vez de 500

# Ou processar em lotes
python exp1_auto_detection.py --batch-size 50
```

---

## üìû SUPORTE

- **Issues**: https://github.com/DeepBridge-Validation/DeepBridge/issues
- **Docs**: `/experimentos/docs/`
- **Roadmap**: `ROADMAP_TIER1.md`

---

**√öltima atualiza√ß√£o**: 2025-12-08
**Vers√£o**: 1.0
